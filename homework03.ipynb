{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1\n",
    "\n",
    "Compute the information gain provided by using the price attribute as the root of the decision tree. Is it more or less\n",
    "valuable than the type or patrons attributes computed in class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Gain(P) = Entropy(D) - Remainder(P)\n",
    "#\n",
    "# Entropy(Domain) = (1.0)Remainder(Price)\n",
    "#                 = (7/12)Entropy($) + (2/12)Entropy($$) + (3/12)Entropy($$$)\n",
    "# Entropy($) = - ((4/7)log(4/7) + (3/7)log(3/7)) * (7/12) = 0.5747\n",
    "# Entropy($$) = - ((1)log(1) + 0 = 0\n",
    "# Entropy($$$) = - ((2/3)log(2/3) + (1/3)log(1/3)) * (3/12) = 0.2296\n",
    "#\n",
    "# Remainder(Price) = 0.5747 + 0 + 0.2296 = 0.8043\n",
    "#\n",
    "# Gain(H) = 1 - 0.8043 = 0.1957"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is more effective to ask the Patrons question because the information gain is 0.54 compared to this information gain \n",
    "of only 0.1957."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2\n",
    "\n",
    "In class, we attempted to create by hand a neural network that computes the XOR function. If this was possible, see if \n",
    "you can simplify the network we built. Consider relaxing the conventions of densely-connected, sequential layers. If it \n",
    "was not possible, give a full explanation why it canâ€™t be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most simple neural network that can compute the XOR function has four total nodes and one\n",
    "# hidden layer. There are two initial inputs that go to a single node in the hidden layer, \n",
    "# which then goes to the final output node. The hidden node is an AND node and the output node \n",
    "# is an OR node.\n",
    "#\n",
    "# INPUT1 _______\n",
    "#        \\      \\______ (+1)\n",
    "#    (+1) \\            \\____\n",
    "#          \\                \\\n",
    "#            AND (1.5) ------ OR (0.5) ------>\n",
    "#          /            ____/\n",
    "#    (+1) /      ______/\n",
    "#        /______/       (+1)\n",
    "# INPUT2\n",
    "#\n",
    "# I found a figure online that helped explain this. The weights that it gives are included in\n",
    "# the diagram above. The edges weights from the inputs to the AND node and OR node are all +1\n",
    "# and the edge weight from the AND node to the OR node is -2. The activation threshold for the\n",
    "# AND node is 1.5 and the activation threshold for the OR node (the output node) is 0.5. (The\n",
    "# only thing not included in the diagram is the (-2) going from the hidden node to the output\n",
    "# node because I didn't know how to include it but keep the diagram readable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3\n",
    "\n",
    "a) Compute the dimensions of the data structures. Include code to print these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "\tcount: 404\n",
      "\tdimensions: 2\n",
      "\tshape: (404, 13)\n",
      "\ttrain_shape: (404,)\n",
      "\tdata type: float64\n",
      "\n",
      "testing set\n",
      "\tcount: 102\n",
      "\tdimensions: 1\n",
      "\tshape: (102, 13)\n",
      "\ttest shape: (102,)\n",
      "\tdata type: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "(train_set, train_y), (test_set, test_y) = boston_housing.load_data()\n",
    "\n",
    "def printstructures():\n",
    "    print('training set\\n\\tcount: {}\\n\\tdimensions: {}'.format(len(train_set), train_set.ndim))\n",
    "    print('\\tshape: {}\\n\\ttrain_shape: {}\\n\\tdata type: {}\\n'.format(train_set.shape, train_y.shape, train_set.dtype))\n",
    "    print('testing set\\n\\tcount: {}\\n\\tdimensions: {}'.format(len(test_y), train_y.ndim))\n",
    "    print('\\tshape: {}\\n\\ttest shape: {}\\n\\tdata type: {}\\n'.format(test_set.shape, test_y.shape, test_y.dtype))\n",
    "\n",
    "printstructures()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "b) Construct a suitable testing set, training set, and validation set for this data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# make testing set and training set dataframes\n",
    "training_data = pd.DataFrame(train_set)\n",
    "training_data['target'] = train_y\n",
    "testing_data = pd.DataFrame(test_set)\n",
    "testing_data['target'] = test_y\n",
    "\n",
    "# reindex to randomize the splitting\n",
    "training_data = training_data.reindex(np.random.permutation(training_data.index))\n",
    "\n",
    "# split 80/20 into the training and testing sets\n",
    "validation_data = training_data.tail(81)\n",
    "training_data = training_data.head(323)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "c) Create one new synthetic feature that could be useful for machine learning in this domain. Explain what it is and why\n",
    "it might be useful, and submit code to add it to the dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def synthetic_frame(data_frame):\n",
    "    data_frame['tax_per_room'] = data_frame[9] / data_frame[5]\n",
    "    return data_frame\n",
    "\n",
    "validation_data = synthetic_frame(validation_data)\n",
    "training_data = synthetic_frame(training_data)\n",
    "testing_data = synthetic_frame(testing_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I used TAX (the full-value property tax rate) and RM (the average number of rooms per dwelling) to create a synthetic\n",
    "feature that shows us the tax rate per room."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}